{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3db990c",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "\n",
    "The goal of this notebook is to provide a quick demonstration of XGBoost in conjunction with \"traditional\" sklearn processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1800e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e271d97",
   "metadata": {},
   "source": [
    "We will play with the [eye movements dataset](https://www.openml.org/search?type=data&sort=runs&id=1044&status=active) from openml.\n",
    "\n",
    "It contains various eye movements metrics measured as participants scan a list of news titles.\n",
    "\n",
    "The setup is that participants are given a question, and then are presented 10 news titles. 5 are irrelevant to the question asked, 4 are relevant but do not answer the question, and 1 is relevant and answers the question.\n",
    "\n",
    "The original data presents the eye movements metrics for each single words in the titles, for the sake of simplifying the data structure (which should normaly account for dependency between words in the same title and so on), we have aggregated the words by title for each assignment (we used a mean aggregation).\n",
    "\n",
    "\n",
    "The target is encoded as:\n",
    " * 0 : title irrelevant\n",
    " * 1 : title relevant but does not answer the question\n",
    " * 2 : title relevant and answers the question\n",
    "\n",
    "The features are:\n",
    " * **fixcount** Number of fixations to the word \n",
    " * **firstPassCnt** Number of fixations to the word when it is first encountered \n",
    " * **P1stFixation** '1' if fixation occured when the sentence the word was in was encountered the first time \n",
    " * **P2stFixation** '1' if fixation occured when the sentence the word was in was encountered the second time \n",
    " * **prevFixDur** Duration of previous fixation \n",
    " * **firstfixDur** Duration of the first fixation when the word is first encountered \n",
    " * **firstPassFixDur** Sum of durations of fixations when the word is first encountered \n",
    " * **nextFixDur** Duration of the next fixation when gaze initially moves from the word \n",
    " * **firstSaccLen** Length of the first saccade \n",
    " * **lastSaccLen** Distance between fixation on the word and the next fixation \n",
    " * **prevFixPos** Distance between the first fixation preceding the word and the beginning ot the word \n",
    " * **landingPos** Distance between the first fixation on the word and the beginning of the word \n",
    " * **leavingPos** Distance between the last fixation on the word and the beginning of the word \n",
    " * **totalFixDur** Sum of all durations of fixations to the word \n",
    " * **meanFixDur** Mean duration of the fixations to the word \n",
    " * **nRegressFrom** Number of regressions leaving from the word \n",
    " * **regressLen** Sum of durations of regressions initiating from this word \n",
    " * **nextWordRegress** '1' if a regression initiated from the following word \n",
    " * **regressDur** Sum of durations of the fixations on the word during regression \n",
    " * **pupilDiamMax** Maximum pupil diameter \n",
    " * **pupilDiamLag** Maximum pupil diameter 0.5 - 1.5 seconds after the beginning of fixation \n",
    " * **timePrtctg** First fixation duration divided by the total number of fixations \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2aa858",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_movements = pd.read_csv(\"../data/eye_movements_aggregated.csv\")\n",
    "eye_movements.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70846224",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_movements.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5190fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_features = eye_movements.loc[:,['fixcount', 'firstPassCnt', 'P1stFixation', 'P2stFixation',\n",
    "       'prevFixDur', 'firstfixDur', 'firstPassFixDur', 'nextFixDur',\n",
    "       'firstSaccLen', 'lastSaccLen', 'prevFixPos', 'landingPos', 'leavingPos',\n",
    "       'totalFixDur', 'meanFixDur', 'nRegressFrom', 'regressLen',\n",
    "       'nextWordRegress', 'regressDur', 'pupilDiamMax', 'pupilDiamLag',\n",
    "       'timePrtctg']]\n",
    "labels = eye_movements['target'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fdcb24",
   "metadata": {},
   "source": [
    "# a simple XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef469635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xt ,Xv , yt, yv = train_test_split(eye_features , labels , stratify=labels)\n",
    "\n",
    "print(f\"train set length: {len(yt)}\")\n",
    "print(f\"valid set length: {len(yv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecff5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(n_jobs=multiprocessing.cpu_count()-2)\n",
    "\n",
    "xgb_model.fit( Xt, yt)\n",
    "\n",
    "pd.crosstab( yv, xgb_model.predict(Xv) ,  rownames=['true'], colnames=['predicted'] )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae4c27b",
   "metadata": {},
   "source": [
    "We can integrate this classifier seemlessly in other sklearn routine such as gridSearchCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcb4779",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(n_jobs=multiprocessing.cpu_count()-2)\n",
    "\n",
    "# Make sure the number of threads is balanced.\n",
    "clf = GridSearchCV(\n",
    "    xgb_model,\n",
    "    {\"max_depth\": [2, 4, 6], \"n_estimators\": [50, 100, 200], 'eta' : [0.01,0.1,1.0]},\n",
    "    scoring='roc_auc_ovr',\n",
    "    verbose=1,\n",
    "    n_jobs=1,\n",
    ")\n",
    "clf.fit(Xt, yt)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c035457f",
   "metadata": {},
   "source": [
    "\n",
    "# tree method and max bin number: \n",
    "\n",
    "[treemethod](https://xgboost.readthedocs.io/en/stable/treemethod.html)\n",
    "\n",
    "exact , approx, hist, corresponding to different degrees of speed and performance.\n",
    "\n",
    "\n",
    "\n",
    " * `approx` or `hist` should generally be prefered\n",
    " * Most of the time using hist with higher `max_bin` can achieve similar or even superior accuracy while maintaining good performance.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db920573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "## recording training time and performance gain\n",
    "## for different values of max_bin\n",
    "\n",
    "time_list = []\n",
    "scores = []\n",
    "mb_list = []\n",
    "\n",
    "for mb in [2,4,8,16,32,64,128,256,512,1024]:\n",
    "\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_jobs=multiprocessing.cpu_count(),\n",
    "        tree_method=\"hist\" , max_bin = mb )\n",
    "\n",
    "\n",
    "    t1 = time()\n",
    "    cv_score = cross_val_score(xgb_model , eye_features, labels , cv = 5, scoring='roc_auc_ovr')\n",
    "    time_list.append( time()-t1 )\n",
    "    \n",
    "    scores.append( cv_score.mean() )\n",
    "    mb_list.append( mb )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f31412",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,2,figsize = (10,5))\n",
    "ax[0].scatter( mb_list , time_list )\n",
    "ax[1].scatter( mb_list , scores )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685c113c",
   "metadata": {},
   "source": [
    "# XGBoost number of estimators, eta,  and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bdfa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "##let's start by splitting the data into a train and a validaiton set\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(eye_features, labels , stratify=labels, random_state=94)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343e2101",
   "metadata": {},
   "source": [
    "The XGB object lets us use a validation set to monitor the model during the different iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90434171",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(tree_method=\"hist\", \n",
    "                        eval_metric = \"auc\", n_estimators=10)\n",
    "\n",
    "xgb_model.fit(X_train, y_train, eval_set=[(X_train, y_train),(X_valid, y_valid)] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4060339",
   "metadata": {},
   "source": [
    "we can access this data in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48826e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.evals_result_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1137a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot( xgb_model.evals_result_['validation_0']['auc'] , label='train')\n",
    "plt.plot( xgb_model.evals_result_['validation_1']['auc'] , label='validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfc6bbc",
   "metadata": {},
   "source": [
    "After some point we reach a plateau, and then we start over-fitting the train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbebec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_jobs=multiprocessing.cpu_count()-2,\n",
    "    eta = 0.3 , n_estimators=100 , \n",
    "    eval_metric= 'auc' )\n",
    "\n",
    "xgb_model.fit(X_train , y_train  , \n",
    "              eval_set=[(X_train, y_train),(X_valid, y_valid)],\n",
    "              verbose=False )\n",
    "    \n",
    "plt.plot( xgb_model.evals_result_['validation_0']['auc'] , label='train')\n",
    "plt.plot( xgb_model.evals_result_['validation_1']['auc'] , label='validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2899c33a",
   "metadata": {},
   "source": [
    "`eta` controls how fast we learn.\n",
    "\n",
    " * lower value: slower learning\n",
    " * higher value: faster learning, but potentially unstable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e69d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_jobs=multiprocessing.cpu_count()-2,\n",
    "    tree_method=\"hist\" , eta = 0.05 , n_estimators=100 , \n",
    "    eval_metric= 'auc' )\n",
    "\n",
    "xgb_model.fit(X_train , y_train  , \n",
    "              eval_set=[(X_train, y_train),(X_valid, y_valid)],\n",
    "              verbose=False )\n",
    "    \n",
    "plt.plot( xgb_model.evals_result_['validation_0']['auc'] , label='train')\n",
    "plt.plot( xgb_model.evals_result_['validation_1']['auc'] , label='validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39646753",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_jobs=multiprocessing.cpu_count()-2,\n",
    "    tree_method=\"hist\" , eta = 0.5 , n_estimators=100 , \n",
    "    eval_metric= 'auc' )\n",
    "\n",
    "xgb_model.fit(X_train , y_train  , \n",
    "              eval_set=[(X_train, y_train),(X_valid, y_valid)],\n",
    "              verbose=False )\n",
    "    \n",
    "plt.plot( xgb_model.evals_result_['validation_0']['auc'] , label='train')\n",
    "plt.plot( xgb_model.evals_result_['validation_1']['auc'] , label='validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d881d717",
   "metadata": {},
   "source": [
    "Then of course we may want to stop the iterations when we observe a decrease of the validation performance: that's **early stopping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4da1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## early stopping\n",
    "\n",
    "clf = xgb.XGBClassifier(tree_method=\"hist\", \n",
    "                        early_stopping_rounds=5 , \n",
    "                        eval_metric = \"auc\",\n",
    "                        eta = 0.05 )\n",
    "clf.fit(X_train, y_train, eval_set=[(X_train, y_train),(X_valid, y_valid)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba74146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_iteration , clf.best_score #  These are used by the predict() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265d8fe8",
   "metadata": {},
   "source": [
    "Early stopping is great to balance the number of estimators and eta, but, as noted in the [XGBoost doc](https://xgboost.readthedocs.io/en/stable/python/sklearn_estimator.html#early-stopping):\n",
    "\n",
    "\"\"\"\n",
    " However, using **early stopping during cross validation may not be a perfect approach because it changes the model’s number of trees for each validation fold, leading to different model.** A better approach is to retrain the model after cross validation using the best hyperparameters along with early stopping. If you want to experiment with idea of using cross validation with early stopping, here is a snippet to begin with:. However, using early stopping during cross validation may not be a perfect approach because it changes the model’s number of trees for each validation fold, leading to different model. A better approach is to retrain the model after cross validation using the best hyperparameters along with early stopping. \n",
    " \n",
    " \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c119c373",
   "metadata": {},
   "source": [
    "We can use it here to evaluate the effect of `eta`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7dad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a0f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "best_scores = []\n",
    "num_rounds = []\n",
    "etas = np.logspace(-3,0,50)\n",
    "for eta in etas:\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_jobs=multiprocessing.cpu_count()-2,\n",
    "        early_stopping_rounds=10 ,\n",
    "        eta = eta , n_estimators=500 , \n",
    "        eval_metric= 'auc' )\n",
    "\n",
    "    xgb_model.fit(X_train , y_train  , \n",
    "                  eval_set=[(X_train, y_train),(X_valid, y_valid)],\n",
    "                  verbose=False )\n",
    "\n",
    "    best_scores.append( xgb_model.best_score )\n",
    "    num_rounds.append( xgb_model.best_iteration )\n",
    "\n",
    "fig,ax=plt.subplots(1,2,figsize = (10,5))\n",
    "ax[0].plot( etas , best_scores )\n",
    "ax[0].set_xlabel('eta')\n",
    "ax[0].set_ylabel('score')\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].grid()\n",
    "\n",
    "ax[1].plot( etas , num_rounds )\n",
    "ax[1].set_xlabel('eta')\n",
    "ax[1].set_ylabel('number of rounds')\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37e20c4",
   "metadata": {},
   "source": [
    "## exercise: \n",
    "\n",
    "Test the effect of the `subsample` parameter on XGboost. This argument can take values from 0.0 to 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459c74d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_xgb_subsample.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ce7169",
   "metadata": {},
   "source": [
    "# (some of) XGBoost hyper-parameters to control overfitting\n",
    "\n",
    "from the [recommendations on controling overfitting from the documentation](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html#control-overfitting)\n",
    "\n",
    "\n",
    "\n",
    " * The first way is to directly control model complexity.\n",
    "     * This includes `max_depth`, `min_child_weight` and `gamma`.\n",
    "\n",
    " * The second way is to add randomness to make training robust to noise.\n",
    "     * This includes `subsample` and `colsample_bytree`.\n",
    "     * You can also reduce stepsize `eta`. Remember to increase `num_round` when you do so.\n",
    "\n",
    "\n",
    "We have already looked at `eta` and `subsample` together.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e7aa12",
   "metadata": {},
   "source": [
    "## max_depth\n",
    "\n",
    "max_depth (Optional[int]) – Maximum tree depth for base learners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975b3695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make a helper function to facilitate our work\n",
    "def test_param( param_name, param_values, **kwargs ):\n",
    "\n",
    "    best_scores_val = []\n",
    "    best_scores_train = []\n",
    "  \n",
    "    for value in param_values:\n",
    "        xgb_model = xgb.XGBClassifier(\n",
    "            n_jobs=multiprocessing.cpu_count()-2,\n",
    "            early_stopping_rounds=10 ,\n",
    "            eval_metric= 'auc',\n",
    "            **kwargs,\n",
    "            **{param_name:value} \n",
    "        )\n",
    "\n",
    "        xgb_model.fit(X_train , y_train  , \n",
    "                      eval_set=[(X_train, y_train),(X_valid, y_valid)],\n",
    "                      verbose=False )\n",
    "\n",
    "        best_scores_val.append( xgb_model.best_score )\n",
    "        best_scores_train.append( xgb_model.evals_result_['validation_0']['auc'][xgb_model.best_iteration] )\n",
    "        \n",
    "\n",
    "\n",
    "    return param_values , best_scores_val , best_scores_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1c7d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta=0.1\n",
    "n_estimators = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d11104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pname = 'max_depth'\n",
    "pvals = np.arange(1,20)\n",
    "\n",
    "param_values , best_scores_val , best_scores_train = test_param( pname, pvals , \n",
    "                                                                eta=eta , n_estimators=n_estimators)\n",
    "fig,ax=plt.subplots(1,1,figsize = (10,5))\n",
    "ax.plot( param_values , best_scores_val , label = 'validation set' )\n",
    "ax.plot( param_values , best_scores_train , label = 'train set' )\n",
    "ax.set_xticks( param_values )\n",
    "ax.set_xlabel(pname)\n",
    "ax.set_ylabel('score')\n",
    "ax.grid()\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe613ce",
   "metadata": {},
   "source": [
    "## gamma\n",
    "\n",
    "gamma (Optional[float]) – (min_split_loss) Minimum loss reduction required to make a further partition on a leaf node of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbdbd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pname = 'gamma'\n",
    "pvals = np.linspace(0.0,40,100)\n",
    "\n",
    "param_values , best_scores_val , best_scores_train = test_param( pname, pvals,\n",
    "                                                               eta=eta , n_estimators=n_estimators)\n",
    "fig,ax=plt.subplots(1,1,figsize = (10,5))\n",
    "ax.plot( param_values , best_scores_val , label = 'validation set' )\n",
    "ax.plot( param_values , best_scores_train , label = 'train set' )\n",
    "#ax.set_xticks( param_values )\n",
    "ax.set_xlabel(pname)\n",
    "ax.set_ylabel('score')\n",
    "ax.grid()\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4d0843",
   "metadata": {},
   "source": [
    "## min_child_weight\n",
    "\n",
    "min_child_weight (Optional[float]) – Minimum sum of instance weight(hessian) needed in a child."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec1da06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pname = 'min_child_weight'\n",
    "pvals = np.linspace(0.0,200,50)\n",
    "\n",
    "param_values , best_scores_val , best_scores_train = test_param( pname, pvals,\n",
    "                                                               eta=eta , n_estimators=n_estimators)\n",
    "fig,ax=plt.subplots(1,1,figsize = (10,5))\n",
    "ax.plot( param_values , best_scores_val , label = 'validation set' )\n",
    "ax.plot( param_values , best_scores_train , label = 'train set' )\n",
    "#ax.set_xticks( param_values )\n",
    "ax.set_xlabel(pname)\n",
    "ax.set_ylabel('score')\n",
    "ax.grid()\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99255c71",
   "metadata": {},
   "source": [
    "## colsample_bytree\n",
    "\n",
    "colsample_bytree (Optional[float]) – Subsample ratio of columns when constructing each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c096d20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pname = 'colsample_bytree'\n",
    "pvals = np.linspace(0.1,1.0,50)\n",
    "\n",
    "param_values , best_scores_val , best_scores_train = test_param( pname, pvals ,\n",
    "                                                               eta=eta , n_estimators=n_estimators)\n",
    "fig,ax=plt.subplots(1,1,figsize = (10,5))\n",
    "ax.plot( param_values , best_scores_val , label = 'validation set' )\n",
    "ax.plot( param_values , best_scores_train , label = 'train set' )\n",
    "#ax.set_xticks( param_values )\n",
    "ax.set_xlabel(pname)\n",
    "ax.set_ylabel('score')\n",
    "ax.grid()\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c172ae",
   "metadata": {},
   "source": [
    "And these are just some of the main hyper-parameters.\n",
    "\n",
    "**micro-exercise:**\n",
    "what may be missing from the hyper-parameter explorations we have done here?\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6812c479",
   "metadata": {},
   "source": [
    "# Annex : \n",
    "\n",
    "I put here some additional remarks and tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213f38db",
   "metadata": {},
   "source": [
    "## Imbalance\n",
    "\n",
    "https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html#handle-imbalanced-dataset\n",
    "\n",
    "the documentation recommends to use `scale_pos_weight`, which corresponds to the re-weigthing of the positive class samples\n",
    "\n",
    "typical value num_negative_samples / num_positive_samples\n",
    "\n",
    "Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b8337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "B = 0.99\n",
    "X , y = make_classification(n_samples=3*10**3 , weights=[B,1-B])\n",
    "\n",
    "Xt, Xv, yt, yv = train_test_split(X, y, stratify=y, random_state=89)\n",
    "\n",
    "num_pos = yt.sum()\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_jobs=multiprocessing.cpu_count()-2, \n",
    "    early_stopping_rounds=10 ,\n",
    "    eval_metric= 'auc',\n",
    "    scale_pos_weight =  (len(yt) - num_pos) / num_pos )\n",
    "\n",
    "\n",
    "xgb_model.fit(Xt , yt  , \n",
    "                  eval_set=[(Xt, yt),(Xv, yv)],\n",
    "                  verbose=False )\n",
    "print( xgb_model.best_score )\n",
    "\n",
    "pd.crosstab( yv,  xgb_model.predict( Xv ) ,  rownames=['true'], colnames=['predicted'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ad5796",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.datasets import make_classification\n",
    "prop_zeros = np.logspace( np.log10(0.5) , np.log10(1-10**-3) , 50 )\n",
    "auc_no_weights = []\n",
    "auc_with_weights = []\n",
    "recall_with_weight = []\n",
    "recall_no_weight = []\n",
    "\n",
    "for B in prop_zeros:\n",
    "    X , y = make_classification(n_samples=3*10**3 , weights=[B,1-B])\n",
    "\n",
    "    Xt, Xv, yt, yv = train_test_split(X, y, stratify=y, random_state=89)\n",
    "\n",
    "    num_pos = yt.sum()\n",
    "\n",
    "    ## with weights\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_jobs=multiprocessing.cpu_count()-2, \n",
    "        early_stopping_rounds=10 ,\n",
    "        eval_metric= 'auc',\n",
    "        scale_pos_weight = (len(yt) - num_pos) / num_pos )\n",
    "\n",
    "\n",
    "    xgb_model.fit(Xt , yt  , \n",
    "                      eval_set=[(Xt, yt),(Xv, yv)],\n",
    "                      verbose=False )\n",
    "    auc_with_weights.append( xgb_model.best_score )\n",
    "    recall_with_weight.append( ( xgb_model.predict( Xv )[yv==1] ==1 ).mean() )\n",
    "    ## without weights\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_jobs=multiprocessing.cpu_count()-2, \n",
    "        early_stopping_rounds=10 ,\n",
    "        eval_metric= 'auc')\n",
    "\n",
    "\n",
    "    xgb_model.fit(Xt , yt  , \n",
    "                      eval_set=[(Xt, yt),(Xv, yv)],\n",
    "                      verbose=False )\n",
    "    auc_no_weights.append( xgb_model.best_score )\n",
    "    \n",
    "    recall_no_weight.append( ( xgb_model.predict( Xv )[yv==1] ==1 ).mean() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0185e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot( prop_zeros , auc_no_weights , label=\"no re-weigthing\" )\n",
    "plt.plot( prop_zeros , auc_with_weights , label=\"re-weigthing\" )\n",
    "plt.xlabel('imbalance')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cada13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot( prop_zeros , recall_no_weight , label=\"no re-weigthing\" )\n",
    "plt.plot( prop_zeros , recall_with_weight , label=\"re-weigthing\" )\n",
    "plt.xlabel('imbalance')\n",
    "plt.ylabel('recall')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0956326b",
   "metadata": {},
   "source": [
    "The effect is not extremely clear here, but recall tends to be better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203e222f",
   "metadata": {},
   "source": [
    "## trick: continuing training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f1e749",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_jobs=multiprocessing.cpu_count()-2,\n",
    "    tree_method=\"hist\" , eta = 0.3 , n_estimators=32  )\n",
    "\n",
    "xgb_model.fit(X_train , y_train)\n",
    "\n",
    "print( \"first call to fit:\", xgb_model.get_booster().num_boosted_rounds() , 'rounds')\n",
    "\n",
    "xgb_model.fit(X_train , y_train  ,xgb_model=xgb_model )\n",
    "\n",
    "print( \"second call to fit:\", xgb_model.get_booster().num_boosted_rounds() , 'rounds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c98da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb32746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01743360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_intermediateml_2024)",
   "language": "python",
   "name": "conda_intermediateml_2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
