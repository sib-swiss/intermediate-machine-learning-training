{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a010f163",
   "metadata": {},
   "source": [
    "# Hyperopt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029081c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5e2afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we start again by reading our data\n",
    "\n",
    "eye_movements = pd.read_csv(\"../data/eye_movements_aggregated.csv\")\n",
    "eye_movements.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e04e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_movements.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b182eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_features = eye_movements.loc[:,['fixcount', 'firstPassCnt', 'P1stFixation', 'P2stFixation',\n",
    "       'prevFixDur', 'firstfixDur', 'firstPassFixDur', 'nextFixDur',\n",
    "       'firstSaccLen', 'lastSaccLen', 'prevFixPos', 'landingPos', 'leavingPos',\n",
    "       'totalFixDur', 'meanFixDur', 'nRegressFrom', 'regressLen',\n",
    "       'nextWordRegress', 'regressDur', 'pupilDiamMax', 'pupilDiamLag',\n",
    "       'timePrtctg']]\n",
    "labels = eye_movements['target'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba0d5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d6abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##let's start by splitting the data into a train and a validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(eye_features, labels, test_size=0.2, random_state=123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12e8dfb",
   "metadata": {},
   "source": [
    "we train a model to gain an idea of baseline performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d0c87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBClassifier(n_jobs=multiprocessing.cpu_count()-2)\n",
    "\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eadf233",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'train st performance:',roc_auc_score(y_train , xgb_model.predict_proba( X_train ) , multi_class='ovr' ) )\n",
    "print( 'valid set performance:',roc_auc_score(y_valid , xgb_model.predict_proba( X_valid ) , multi_class='ovr') )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd12f51",
   "metadata": {},
   "source": [
    "# \"basic\" usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589ec727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, rand, pyll, STATUS_OK, STATUS_FAIL, Trials, space_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d8a61e",
   "metadata": {},
   "source": [
    "## function to optimize\n",
    "\n",
    "We need to write a function which :\n",
    " * takes a dictionary of parameters as arguments\n",
    " * returns a dictionnary containing the computed loss and a status value\n",
    " \n",
    "Importantly, the loss is a value which we want to **minimize**, so in our case we will\n",
    "use -AUC(validation data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea99e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hyperopt_xgb_train( params ):\n",
    "    \n",
    "    xgb_model = xgb.XGBClassifier(n_jobs=multiprocessing.cpu_count()-2 , **params)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    loss = -roc_auc_score(y_valid , xgb_model.predict_proba( X_valid ) , multi_class='ovr' )\n",
    "    return_dict = {'loss': loss,\n",
    "                   'status': STATUS_OK\n",
    "                   }\n",
    "    return return_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc53f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict( n_estimators=100,\n",
    "               eta = 0.3,\n",
    "               subsample = 0.8,\n",
    "               max_depth = 5)\n",
    "hyperopt_xgb_train( params )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c869418e",
   "metadata": {},
   "source": [
    "## parameter search-space\n",
    "\n",
    "The way it works is that for each hyper-parameter you define a **prior distribution** (it is bayesian afterall) using one of hyperopt function.\n",
    "\n",
    "For a more detailed documentation we refer you to the [hyperopt documentation](http://hyperopt.github.io/hyperopt/getting-started/search_spaces/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729cae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_uniform = hp.uniform('simple', 0, 1)\n",
    "simple_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f6ee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyll.stochastic.sample(simple_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9fd710",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = hp.loguniform('eta' , np.log(10**-4) , np.log(10**2) )\n",
    "pyll.stochastic.sample(eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787089a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot( [ np.log10( pyll.stochastic.sample(eta) ) for _ in range(10000) ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071710ce",
   "metadata": {},
   "source": [
    "**exercise** : which prior distribution could we give `n_estimators`? to `max_depth` ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7826a1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2931b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_hyperopt_parameter_space.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c547424d",
   "metadata": {},
   "source": [
    "## minimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9ab689",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(hyperopt_xgb_train, \n",
    "            space4xgb, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals=20, \n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006e8f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96396908",
   "metadata": {},
   "outputs": [],
   "source": [
    "len( trials )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60018ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials.trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b261eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials.results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a58623",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials.losses()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6194ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials.vals.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26baf8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in trials.vals.keys():\n",
    "    print(k , trials.vals[k][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5b496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "sns.kdeplot( np.log10( trials.vals['eta'] ) , ax=ax , cut = 0 , label='sampled')\n",
    "sns.histplot( np.log10( trials.vals['eta'] ) , binwidth=0.5 , ax=ax , label='sampled' , stat = 'density')\n",
    "\n",
    "sns.kdeplot( [ np.log10( pyll.stochastic.sample(eta) ) for _ in range(10000) ] , ax=ax , cut = 0 , label='prior')\n",
    "ax.set_xlabel('eta')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf698f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax = sns.scatterplot( x = np.log10( trials.vals['eta'] ) ,\n",
    "                 y =  trials.losses() )\n",
    "ax.set_xlabel('eta')\n",
    "ax.set_ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f10b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot( x =  range(len(trials.losses())) ,  y =  trials.losses() )\n",
    "ax.set_xlabel('trials')\n",
    "ax.set_ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef0e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8130d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15d7781c",
   "metadata": {},
   "source": [
    "# changing the cross-validation scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af2ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9dc3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5 , shuffle=True , random_state = 2024 )\n",
    "for t,v in skf.split( eye_features, labels ):\n",
    "\n",
    "    print(len(t), t[:5])\n",
    "    print(len(v), v[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550c042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score( xgb.XGBClassifier(n_jobs=multiprocessing.cpu_count()-2) , \n",
    "                eye_features, labels, scoring = 'roc_auc_ovr' , cv = skf )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00646d1",
   "metadata": {},
   "source": [
    "### exercise\n",
    "\n",
    "Write the function we will give to `fmin` to evaluate an XGBoost classifier with 5-fold CV with a ROC AUC score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de44ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_xgb_train_CV5( params ):\n",
    "    ...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceea5c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/solution_hyperopt_CV.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc1b8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use this code to test your function:\n",
    "params = dict( n_estimators=100,\n",
    "               eta = 0.3,\n",
    "               subsample = 0.8,\n",
    "               max_depth = 5)\n",
    "hyperopt_xgb_train_CV5( params )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d39b4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trials = Trials()\n",
    "\n",
    "best = fmin(hyperopt_xgb_train_CV5, \n",
    "            space4xgb, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals=10, \n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8a1f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "len( trials )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17d5f82",
   "metadata": {},
   "source": [
    "# warm start : continue searching for better solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd76e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = fmin(hyperopt_xgb_train_CV5, \n",
    "            space4xgb, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals=14, \n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d6f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e69e5ea",
   "metadata": {},
   "source": [
    "# nested search space\n",
    "\n",
    "It is possible nest elements in `hp.choice()` or `hp.pchoice()` to specify more complex search spaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b8de63",
   "metadata": {},
   "outputs": [],
   "source": [
    "space4nested = hp.pchoice('classifier_type',\n",
    "                          [(0.6, {'classifier_type': 'xgboost',\n",
    "                                    'n_estimators': pyll.scope.int(hp.quniform('n_estimators', 1 , 1000,1)),\n",
    "                                    'eta': hp.loguniform('eta' , np.log(10**-4) , np.log(10**2) ),\n",
    "                                    'max_depth': pyll.scope.int(hp.quniform('max_depth', 1, 16, 1)),\n",
    "                                    'subsample': hp.uniform('subsample', 0.3, 1)\n",
    "                                  }\n",
    "                            ),\n",
    "                           (0.4, {'classifier_type': 'logistic regression',\n",
    "                                  'C': hp.loguniform(\"C\", low=np.log(1e-5), high=np.log(1e2)),\n",
    "                                  'penalty': hp.choice('penalty', ['l1','l2'])\n",
    "                                  }\n",
    "                            )]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c2bf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "def hyperopt_complex_train_CV5( params ):\n",
    "    \n",
    "    classif_type = params.pop('classifier_type')\n",
    "    \n",
    "    model = None\n",
    "    if classif_type == 'xgboost':\n",
    "        model = xgb.XGBClassifier(n_jobs=multiprocessing.cpu_count()-2 , **params) \n",
    "    \n",
    "    else:\n",
    "        model =Pipeline([('scalar',StandardScaler()), \n",
    "                      ('model',LogisticRegression(solver ='liblinear', class_weight='balanced', **params))])\n",
    "    \n",
    "    losses = -1 * cross_val_score( model  , \n",
    "                    eye_features, labels, scoring = 'accuracy' , cv = skf )\n",
    "        \n",
    "    return_dict = {'loss': np.mean(losses),\n",
    "                   'loss_variance' : np.var(losses),\n",
    "                   'status': STATUS_OK\n",
    "                   }\n",
    "    return return_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1f2a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "trials = Trials()\n",
    "best = fmin(hyperopt_complex_train_CV5, \n",
    "            space4nested, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals=15, \n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07dc5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials.trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd8b902",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot( x =  range(len(trials.losses())) ,  y =  trials.losses() , \n",
    "                     hue = np.array(['xgboost','logistic regression'])[trials.vals['classifier_type']] )\n",
    "ax.set_xlabel('trials')\n",
    "ax.set_ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e163fb1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fade2148",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_intermediateml_2024)",
   "language": "python",
   "name": "conda_intermediateml_2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
